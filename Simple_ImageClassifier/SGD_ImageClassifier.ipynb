{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SGD_ImageClassifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehoI4_nitpj-",
        "outputId": "e7c99bb3-5982-48ef-e584-4a2f5846b4f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip \"/content/drive/MyDrive/DataScience/Pyimagesearch_DeepLearningBook/Chapter7/archive.zip\" -d \"/content/drive/MyDrive/DataScience/Pyimagesearch_DeepLearningBook/Chapter7/\""
      ],
      "metadata": {
        "id": "TEDkgO_mt0p1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "all_images = []\n",
        "\n",
        "for path, subdirs, files in os.walk(\"/content/drive/MyDrive/DataScience/Pyimagesearch_DeepLearningBook/Chapter7/animals\"):\n",
        "    for name in files:\n",
        "        all_images.append(os.path.join(path, name))\n",
        "\n",
        "len(all_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYDmjtI8wI6y",
        "outputId": "2eff8313-66cc-4841-abe0-307bcbcdce64"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3000"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "\n",
        "class SimplePreprocessor:\n",
        "  def __init__(self, width, height, inter=cv2.INTER_AREA):\n",
        "    self.width = width\n",
        "    self.height = height\n",
        "    self.inter = inter\n",
        "\n",
        "  def preprocess(self, image):\n",
        "    return cv2.resize(image, (self.width, self.height), interpolation = self.inter)"
      ],
      "metadata": {
        "id": "CBR3Hntt33Js"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "class SimpleDatasetLoader:\n",
        "  def __init__(self, preprocessors=None):\n",
        "    self.preprocessors = preprocessors\n",
        "\n",
        "    if self.preprocessors is None:\n",
        "      self.preprocessors = []\n",
        "\n",
        "  def load(self, imagePaths, verbose=-1):\n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    for (i, imagePath) in enumerate(imagePaths):\n",
        "      image = cv2.imread(imagePath)\n",
        "      label = imagePath.split(os.path.sep)[-2]\n",
        "\n",
        "      if self.preprocessors is not None:\n",
        "        for p in self.preprocessors:\n",
        "          image = p.preprocess(image)\n",
        "\n",
        "      data.append(image)\n",
        "      labels.append(label)\n",
        "\n",
        "      if verbose > 0 and i > 0 and (i+1) % verbose == 0:\n",
        "        print(\"[INFO] processed {}/{}\".format(i+1, len(imagePaths)))\n",
        "\n",
        "    return (np.array(data), np.array(labels))\n"
      ],
      "metadata": {
        "id": "OK6wEZkE5IdJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "g6jxNwkx6xtA"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[INFO] loading images..\")\n",
        "\n",
        "sp = SimplePreprocessor(32, 32)\n",
        "\n",
        "sdl = SimpleDatasetLoader(preprocessors=[sp])\n",
        "\n",
        "(data, labels) = sdl.load(all_images, verbose=500)\n",
        "\n",
        "print(data.shape)\n",
        "\n",
        "data = data.reshape((data.shape[0], 3072))\n",
        "\n",
        "print(\"[INFO] feature matrix: {:.1f}MB\".format(data.nbytes / (1024 * 1000.0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyJLuaqm9vYJ",
        "outputId": "bdf2bb8f-6b2c-4172-c2be-b09f9a61a477"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] loading images..\n",
            "[INFO] processed 500/3000\n",
            "[INFO] processed 1000/3000\n",
            "[INFO] processed 1500/3000\n",
            "[INFO] processed 2000/3000\n",
            "[INFO] processed 2500/3000\n",
            "[INFO] processed 3000/3000\n",
            "(3000, 32, 32, 3)\n",
            "[INFO] feature matrix: 9.0MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "labels = le.fit_transform(labels)\n",
        "\n",
        "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "woJz9_UY-Xl8"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for r in (None, 'l1', 'l2'):\n",
        "  print(\"[INFO] training model with '{}' penalty\".format(r))\n",
        "  model = SGDClassifier(loss='log', penalty=r, max_iter=10, learning_rate='constant', eta0=0.01, random_state=42)\n",
        "\n",
        "  model.fit(trainX, trainY)\n",
        "\n",
        "  acc = model.score(testX, testY)\n",
        "  print(\"[INFO] '{}' penalty accuracy: {:0.2f}%\".format(r, acc * 100))"
      ],
      "metadata": {
        "id": "yWD_uSKTBQaU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62e56376-8373-45b7-db29-b96663f7dac7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] training model with 'None' penalty\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] 'None' penalty accuracy: 43.20%\n",
            "[INFO] training model with 'l1' penalty\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] 'l1' penalty accuracy: 42.67%\n",
            "[INFO] training model with 'l2' penalty\n",
            "[INFO] 'l2' penalty accuracy: 53.20%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_stochastic_gradient.py:700: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(testY, model.predict(testX), target_names= le.classes_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZEKt8cPnmAl",
        "outputId": "a69937d5-00ed-41d1-9aa0-c68d373ee3a9"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        cats       0.50      0.57      0.53       262\n",
            "        dogs       0.45      0.24      0.31       249\n",
            "       panda       0.59      0.79      0.68       239\n",
            "\n",
            "    accuracy                           0.53       750\n",
            "   macro avg       0.52      0.53      0.51       750\n",
            "weighted avg       0.51      0.53      0.51       750\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zFbLgA5MrBPx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}